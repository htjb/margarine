# Tutorials and Examples

This document provides a collection of tutorials and examples to help you get started with various topics. Each section includes step-by-step instructions and code snippets to guide you through the process.

## The Basics

`margarine` has several different density estimators that can be used to learn probability distributions from samples. Each estimator has a common interface and set of methods including `train()`, `sample()`, `log_prob()`, `log_like()`, `save()` and `load()`. The following example demonstrates how to train a RealNVP density estimator and generate samples from it. Similar patterns can be followed for other estimators in the library and the API reference can be consulted for specifics.

We first need to generate some example samples to train on. In this case we will generate samples from a 2D Gaussian distribution with some correlation between the two dimensions.

```python
import jax
import jax.numpy as jnp
import matplotlib.pyplot as plt

from margarine.estimators.realnvp import RealNVP

nsamples = 5000
key = jax.random.PRNGKey(0)
original_samples = jax.random.multivariate_normal(
    key,
    mean=jnp.array([0.0, 0.0]),
    cov=jnp.array([[1.0, 0.8], [0.8, 1.0]]),
    shape=(nsamples,),
)
```

We can then create a RealNVP density estimator, train it on the samples, and generate new samples from the learned distribution.

```python
realnvp_estimator = RealNVP(
        original_samples,
        in_size=2,
        hidden_size=50,
        num_layers=6,
        num_coupling_layers=6,
    )
key, subkey = jax.random.split(key)
realnvp_estimator.train(
            subkey,
            learning_rate=1e-3,
            epochs=2000,
            patience=50,
            batch_size=1000,
)
generated_samples = realnvp_estimator.sample(key, num_samples=nsamples)
```

Finally, we can visualize the original samples and the samples generated by the RealNVP estimator to see how well it has learned the distribution.

```python
plt.scatter(
    original_samples[:, 0], original_samples[:, 1], alpha=0.5, label="Original Samples"
)
plt.scatter(
    generated_samples[:, 0], generated_samples[:, 1], alpha=0.5, label="Generated Samples"
)
plt.legend()
plt.title("RealNVP: Original vs Generated Samples")
plt.xlabel("X1")
plt.ylabel("X2")
plt.show()
```

You can also calculate the log-probability of samples under the learned distribution using the `log_prob()` method.

```python
log_probs = realnvp_estimator.log_prob(original_samples)
print("Log probabilities of original samples:", log_probs)
```

and transform samples from a unit hypercube to the learned distribution using `__call__` method.

```python
unit_samples = jax.random.uniform(key, shape=(nsamples, 2))
transformed_samples = realnvp_estimator(unit_samples)
```

This is essentially what the `sample()` method does internally by transforming uniform samples to the learned distribution.

This is just a basic example to get you started. Each density estimator in `margarine` has its own specific parameters and options, so be sure to check the documentation for more details on how to use them effectively.


